{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8221064,"sourceType":"datasetVersion","datasetId":4856165}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install diffusers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T03:34:14.189539Z","iopub.execute_input":"2024-05-08T03:34:14.189883Z","iopub.status.idle":"2024-05-08T03:34:29.262407Z","shell.execute_reply.started":"2024-05-08T03:34:14.189855Z","shell.execute_reply":"2024-05-08T03:34:29.261328Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting diffusers\n  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (6.11.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.22.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (9.5.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.9.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.2.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.2->diffusers) (3.1.1)\nDownloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.27.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install onnxruntime","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:34:29.264419Z","iopub.execute_input":"2024-05-08T03:34:29.264716Z","iopub.status.idle":"2024-05-08T03:34:43.066128Z","shell.execute_reply.started":"2024-05-08T03:34:29.264688Z","shell.execute_reply":"2024-05-08T03:34:43.065200Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting onnxruntime\n  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nCollecting coloredlogs (from onnxruntime)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\nRequirement already satisfied: numpy>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (21.3)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime) (1.12)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->onnxruntime) (3.1.1)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\nDownloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir diffusionSamples","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:34:43.071366Z","iopub.execute_input":"2024-05-08T03:34:43.071650Z","iopub.status.idle":"2024-05-08T03:34:44.032382Z","shell.execute_reply.started":"2024-05-08T03:34:43.071622Z","shell.execute_reply":"2024-05-08T03:34:44.031330Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, MidiProcessor, SpectrogramDiffusionPipeline\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:34:44.033720Z","iopub.execute_input":"2024-05-08T03:34:44.034032Z","iopub.status.idle":"2024-05-08T03:35:00.320981Z","shell.execute_reply.started":"2024-05-08T03:34:44.034003Z","shell.execute_reply":"2024-05-08T03:35:00.320206Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfd14a8f6c404f8d8d86ad718fa12f20"}},"metadata":{}},{"name":"stderr","text":"2024-05-08 03:34:50.914507: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-08 03:34:50.914599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-08 03:34:51.030883: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"pipe = StableDiffusionPipeline.from_pretrained(\"riffusion/riffusion-model-v1\")\npipe = pipe.to(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:35:00.322055Z","iopub.execute_input":"2024-05-08T03:35:00.322694Z","iopub.status.idle":"2024-05-08T03:38:03.427312Z","shell.execute_reply.started":"2024-05-08T03:35:00.322668Z","shell.execute_reply":"2024-05-08T03:38:03.425905Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"702c27038045465b97cf5726866c8e3a"}},"metadata":{}},{"name":"stderr","text":"safety_checker/model.safetensors not found\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c1917a2e4c849feb17d063dcd0d57da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e532272c20b4eaf9b0dac15a06b8a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7040352ad6d648388b2e232817eac7f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler/scheduler_config.json:   0%|          | 0.00/284 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe681b684fd48d0881ee66d6c3bdb88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9340ccb648a4e519882c849b856cb4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"safety_checker/config.json:   0%|          | 0.00/4.84k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea5dc9aff62642eaa4c72dafc06380f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fefd265fe6f049a09fb0651f08cfab7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b113499b9214b919d3311eb7b7b7603"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9241f663cecc4511a7f310ccf35b0a65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbffdc3de3ba450aa574fedad39568de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c0e2249980b4fbe997228df781ea158"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"text_encoder/pytorch_model.bin:   0%|          | 0.00/492M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f4ad84960e748d181f992e8dc6bebf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"safety_checker/pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e31b8b11b4104b6287801fd87fc392bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet/diffusion_pytorch_model.bin:   0%|          | 0.00/3.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44395c7c20d45399ac840912018763f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vae/diffusion_pytorch_model.bin:   0%|          | 0.00/335M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9167ffe6cb45f1ada89213231dea9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a4c9640dae84395848a3195619b669f"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n/opt/conda/lib/python3.10/site-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:236: FutureWarning: The configuration file of the unet has set the default `sample_size` to smaller than 64 which seems highly unlikely. If your checkpoint is a fine-tuned version of any of the following: \n- CompVis/stable-diffusion-v1-4 \n- CompVis/stable-diffusion-v1-3 \n- CompVis/stable-diffusion-v1-2 \n- CompVis/stable-diffusion-v1-1 \n- runwayml/stable-diffusion-v1-5 \n- runwayml/stable-diffusion-inpainting \n you should change 'sample_size' to 64 in the configuration file. Please make sure to update the config accordingly as leaving `sample_size=32` in the config might lead to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `unet/config.json` file\n  deprecate(\"sample_size<64\", \"1.0.0\", deprecation_message, standard_warn=False)\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:38:03.428936Z","iopub.execute_input":"2024-05-08T03:38:03.429534Z","iopub.status.idle":"2024-05-08T03:38:03.679106Z","shell.execute_reply.started":"2024-05-08T03:38:03.429504Z","shell.execute_reply":"2024-05-08T03:38:03.677898Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pipe.scheduler.set_timesteps(50, device=\"cuda\")\nT = pipe.scheduler.timesteps\nT = torch.flip(T, dims=(0,))\nstepsize = 5","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:38:03.680659Z","iopub.execute_input":"2024-05-08T03:38:03.681050Z","iopub.status.idle":"2024-05-08T03:38:03.730797Z","shell.execute_reply.started":"2024-05-08T03:38:03.681014Z","shell.execute_reply":"2024-05-08T03:38:03.729987Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"idxs = range(0, 50, stepsize)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:39:04.977619Z","iopub.execute_input":"2024-05-08T03:39:04.978370Z","iopub.status.idle":"2024-05-08T03:39:04.982618Z","shell.execute_reply.started":"2024-05-08T03:39:04.978336Z","shell.execute_reply":"2024-05-08T03:39:04.981529Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"prompt = \"Soothing slow music\"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:39:28.674202Z","iopub.execute_input":"2024-05-08T03:39:28.675007Z","iopub.status.idle":"2024-05-08T03:39:28.679062Z","shell.execute_reply.started":"2024-05-08T03:39:28.674966Z","shell.execute_reply":"2024-05-08T03:39:28.678149Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"uncond_tokens = [\"\"] * 1\ntext_inputs = pipe.tokenizer(\n    prompt,\n    padding=\"max_length\",\n    max_length=pipe.tokenizer.model_max_length,\n    return_tensors=\"pt\",\n)\ntext_input_ids = text_inputs.input_ids\ntext_embeddings = pipe.text_encoder(text_input_ids.to(device))[0]\n\nbs_embed, seq_len, _ = text_embeddings.shape\ntext_embeddings = text_embeddings.repeat(1, 1, 1)\ntext_embeddings = text_embeddings.view(bs_embed * 1, seq_len, -1)\n\nmax_length = text_input_ids.shape[-1]\nuncond_input = pipe.tokenizer(\n    uncond_tokens,\n    padding=\"max_length\",\n    max_length=max_length,\n    truncation=True,\n    return_tensors=\"pt\",\n)\nuncond_embeddings = pipe.text_encoder(uncond_input.input_ids.to(device))[0]\n\nseq_len = uncond_embeddings.shape[1]\nuncond_embeddings = uncond_embeddings.repeat(1, 1, 1)\nuncond_embeddings = uncond_embeddings.view(1 * 1, seq_len, -1)\n\ntext_embeddings = torch.cat([uncond_embeddings, text_embeddings])","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:39:32.420685Z","iopub.execute_input":"2024-05-08T03:39:32.421518Z","iopub.status.idle":"2024-05-08T03:39:32.460174Z","shell.execute_reply.started":"2024-05-08T03:39:32.421484Z","shell.execute_reply":"2024-05-08T03:39:32.459406Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"latents_list = []\n\ndef callback(iter, t, latents):\n    # convert latents to image\n    with torch.no_grad():\n        latents = 1 / 0.18215 * latents\n        \n        latents_list.append(latents)\n        \n        latent = torch.cat([latents_list[0]] * 2)\n        \n        latent_model_input = pipe.scheduler.scale_model_input(latent, T[idxs[0]])\n        \n        noise_pred = pipe.unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n        \n        noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n        \n        noise_pred = noise_pred_uncond + 7.5 * (noise_pred_text - noise_pred_uncond)\n        \n        noise_pred = 1 / 0.18215 * noise_pred\n    \n        noise_image = pipe.vae.decode(noise_pred).sample\n\n        noise_image = (noise_image / 2 + 0.5).clamp(0, 1)\n\n        # we always cast to float32 as this does not cause significant overhead and is compatible with bfloa16\n        noise_image = noise_image.cpu().permute(0, 2, 3, 1).float().numpy()\n\n        # convert to PIL Images\n        noise_image = pipe.numpy_to_pil(noise_image)\n        \n        image = pipe.vae.decode(latents).sample\n\n        image = (image / 2 + 0.5).clamp(0, 1)\n\n        # we always cast to float32 as this does not cause significant overhead and is compatible with bfloa16\n        image = image.cpu().permute(0, 2, 3, 1).float().numpy()\n\n        # convert to PIL Images\n        image = pipe.numpy_to_pil(image)\n\n        # do something with the Images\n        for i, img in enumerate(image):\n            img.save(f\"diffusionSamples/iter_{iter}_img{i}.png\")\n        \n        for i, img in enumerate(noise_image):\n            img.save(f\"diffusionSamples/noise_pred_iter_{iter}_img{i}.png\")\n\n# generate image (note the `callback` and `callback_steps` argument)\n#image = model(\"tree\", callback=callback, callback_steps=5)\nimage = pipe(prompt, callback=callback, callback_steps=5).images[0]","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:39:33.946090Z","iopub.execute_input":"2024-05-08T03:39:33.946718Z","iopub.status.idle":"2024-05-08T03:39:55.560029Z","shell.execute_reply.started":"2024-05-08T03:39:33.946685Z","shell.execute_reply":"2024-05-08T03:39:55.559036Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfb1f215364b45aba84b731394aab0b3"}},"metadata":{}}]},{"cell_type":"code","source":"image.save(\"soothingSlowMusic.jpg\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:39:57.000717Z","iopub.execute_input":"2024-05-08T03:39:57.001371Z","iopub.status.idle":"2024-05-08T03:39:57.009636Z","shell.execute_reply.started":"2024-05-08T03:39:57.001338Z","shell.execute_reply":"2024-05-08T03:39:57.008891Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"image = Image.open(\"soothingSlowMusic.jpg\").convert(\"RGB\")\nimage = transforms.ToTensor()(image)\n\nimages = []\nfor idx in idxs:\n    t = T[idx]\n    noise = torch.randn_like(image)\n    noisy_image = pipe.scheduler.add_noise(image, noise, t)\n    images.append(noisy_image)\n    \nfor i in range(10):\n    transforms.ToPILImage()(images[i]).save(f\"diffusionSamples/forward_sample_{i}.png\")\n\nt = torch.Tensor([60]).to(\"cuda\").to(torch.int64)\nnoise = torch.randn_like(image)\nnoisy_image = pipe.scheduler.add_noise(image, noise, t)\ntransforms.ToPILImage()(noisy_image)\ntransforms.ToPILImage()(noisy_image).save(f\"diffusionSamples/forward_sample_man_3.png\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:39:58.829390Z","iopub.execute_input":"2024-05-08T03:39:58.830218Z","iopub.status.idle":"2024-05-08T03:39:59.544631Z","shell.execute_reply.started":"2024-05-08T03:39:58.830183Z","shell.execute_reply":"2024-05-08T03:39:59.543856Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"!zip -r diffusionSampleWithNoise.zip ./diffusionSamples/","metadata":{"execution":{"iopub.status.busy":"2024-05-08T03:40:01.611238Z","iopub.execute_input":"2024-05-08T03:40:01.611971Z","iopub.status.idle":"2024-05-08T03:40:03.268156Z","shell.execute_reply.started":"2024-05-08T03:40:01.611939Z","shell.execute_reply":"2024-05-08T03:40:03.267202Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"  adding: diffusionSamples/ (stored 0%)\n  adding: diffusionSamples/noise_pred_iter_20_img0.png (deflated 0%)\n  adding: diffusionSamples/iter_5_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_8.png (deflated 0%)\n  adding: diffusionSamples/iter_25_img0.png (deflated 0%)\n  adding: diffusionSamples/iter_45_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_4.png (deflated 0%)\n  adding: diffusionSamples/iter_40_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_3.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_2.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_35_img0.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_15_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_1.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_5.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_5_img0.png (deflated 0%)\n  adding: diffusionSamples/iter_20_img0.png (deflated 0%)\n  adding: diffusionSamples/iter_35_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_7.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_40_img0.png (deflated 0%)\n  adding: diffusionSamples/iter_50_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_6.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_45_img0.png (deflated 0%)\n  adding: diffusionSamples/iter_10_img0.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_30_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_man_3.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_50_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_0.png (deflated 0%)\n  adding: diffusionSamples/iter_15_img0.png (deflated 0%)\n  adding: diffusionSamples/forward_sample_9.png (deflated 0%)\n  adding: diffusionSamples/iter_30_img0.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_25_img0.png (deflated 0%)\n  adding: diffusionSamples/noise_pred_iter_10_img0.png (deflated 0%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}